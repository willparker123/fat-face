{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ab72128",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: '<!doctype html>'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_549/2627215803.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0mimage_pixels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage_size\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mimage_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0mdata_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m train_data = np.loadtxt(\"mnist_train.csv\", \n\u001b[0m\u001b[1;32m     44\u001b[0m                         delimiter=\",\")\n\u001b[1;32m     45\u001b[0m test_data = np.loadtxt(\"mnist_test.csv\", \n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mloadtxt\u001b[0;34m(fname, dtype, comments, delimiter, converters, skiprows, usecols, unpack, ndmin, encoding, max_rows, like)\u001b[0m\n\u001b[1;32m   1146\u001b[0m         \u001b[0;31m# converting the data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1147\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1148\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mread_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_loadtxt_chunksize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1149\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1150\u001b[0m                 \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mread_data\u001b[0;34m(chunk_size)\u001b[0m\n\u001b[1;32m    997\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    998\u001b[0m             \u001b[0;31m# Convert each value according to its column and store\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 999\u001b[0;31m             \u001b[0mitems\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconverters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1000\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1001\u001b[0m             \u001b[0;31m# Then pack it according to the dtype's nesting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    997\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    998\u001b[0m             \u001b[0;31m# Convert each value according to its column and store\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 999\u001b[0;31m             \u001b[0mitems\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconverters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1000\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1001\u001b[0m             \u001b[0;31m# Then pack it according to the dtype's nesting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mfloatconv\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    734\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'0x'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    735\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromhex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 736\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    738\u001b[0m     \u001b[0mtyp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: '<!doctype html>'"
     ]
    }
   ],
   "source": [
    "urltest = \"https://ufile.io/4o8w7kxc\"\n",
    "urltrain = \"https://ufile.io/f/wc9hf\"\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import inspect\n",
    "\n",
    "sys.path.insert(1, os.path.join(sys.path[0], '..'))\n",
    "\n",
    "import fatapi\n",
    "from fatapi.data import Data\n",
    "from fatapi.model import BlackBox, Model, DensityEstimator, Transformer\n",
    "import numpy as np\n",
    "from fatapi.methods import FACEMethod\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KernelDensity\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# load MNIST dataset from local .csv files\n",
    "image_size = 28 # width and length\n",
    "no_of_different_labels = 10 #  i.e. 0, 1, 2, 3, ..., 9\n",
    "image_pixels = image_size * image_size\n",
    "data_path = \"\"\n",
    "train_data = np.loadtxt(data_path + \"mnist_train.csv\", \n",
    "                        delimiter=\",\")\n",
    "test_data = np.loadtxt(data_path + \"mnist_test.csv\", \n",
    "                       delimiter=\",\")\n",
    "\n",
    "train_imgs = np.asfarray(train_data[:, 1:])\n",
    "train_labels = np.asfarray(train_data[:, :1])\n",
    "test_imgs = np.asfarray(test_data[:, 1:])\n",
    "test_labels = np.asfarray(test_data[:, :1])\n",
    "# load dataset - data to be used by the Model and for counterfactual generation\n",
    "X_train, y_train, X_test, y_test = train_imgs[:, 100], train_labels, test_imgs, test_labels\n",
    "row_indicies = [0,1,2,3,4]\n",
    "for i in row_indicies:\n",
    "    # define subplot\n",
    "    img = X_test[i].reshape((image_size,image_size))\n",
    "    plt.subplot(330 + 1 + i)\n",
    "    # plot raw pixel data\n",
    "    plt.imshow(img, cmap=plt.get_cmap('gray'))\n",
    "plt.show()\n",
    "\n",
    "myencoder = Transformer(transformer=OneHotEncoder())\n",
    "myscaler = Transformer(transformer=StandardScaler())\n",
    "\n",
    "# Data object wrapper for dataset and targets of dataset - dtype provides default column indicies for categoricals/numericals\n",
    "data_X = Data(dataset=X_test, dtype=\"data\")\n",
    "data_y = Data(dataset=y_test, dtype=\"target\")\n",
    "\n",
    "# datapoints in X to be used as factuals, wrapped in a Data object\n",
    "factuals = data_X.get_rows_as_data(row_indicies)\n",
    "# targets of datapoints in X to be used as factual targets, wrapped in a Data object\n",
    "# has to return a boolean \n",
    "def conditionf(**kwargs):\n",
    "    return True\n",
    "\n",
    "# any classifier model with predict, predict_proba, fit and score methods\n",
    "clf = MLPClassifier(random_state=1, max_iter=300)\n",
    "# wrapper for any classifier to be used by Methods / Models\n",
    "blackb = BlackBox(clf)\n",
    "# Model wrapper - includes blackbox and optional encoder, scaler\n",
    "face_model = Model(data_X, data_y, blackbox=blackb, encoder=myencoder, scaler=myscaler)\n",
    "#face_model.train()\n",
    "\n",
    "print(f\"Classes of X_test[:5, :]: {clf.predict(y_test[:5, :])}\")\n",
    "print(f\"Predicted classes of X_test[:5, :]: {clf.predict(X_test[:5, :])}\")\n",
    "print(f\"Classification accuracy: {clf.score(X_test, y_test)}\\n\")\n",
    "\n",
    "print(y_train)\n",
    "\n",
    "# grid search to find a good KernelDensity estimator (sklearn)\n",
    "bandwidths = 10 ** np.linspace(-2, 1, 100)  \n",
    "grid = GridSearchCV(KernelDensity(kernel='gaussian'),\n",
    "                    {'bandwidth': bandwidths},\n",
    "                    cv=20)\n",
    "grid.fit(data_X.dataset)\n",
    "dens_est = grid.best_estimator_\n",
    "\n",
    "# wrapper for any density estimator ('estimator' has to have fit, score_samples) to be used by FACEMethod\n",
    "_dens_est = DensityEstimator(\n",
    "    estimator=dens_est)\n",
    "\n",
    "# the FACE algorithm with most of the parameters available; required parameters and object specification\n",
    "# can be seen in the source code\n",
    "face_method = FACEMethod(factuals=factuals, \n",
    "                         factuals_target=factuals_target, \n",
    "                         model=face_model, kernel_type=\"kde\", \n",
    "                         t_prediction=0.5, epsilon=0.7,\n",
    "                         t_density=0.0, t_radius_limit=1.10, n_neighbours=20,\n",
    "                         K=10, conditions=conditionf, density_estimator=_dens_est)\n",
    "# the main explain() method to generate counterfactuals\n",
    "print(f\"Counterfactuals (return of explain()): {face_method.explain()}\\n\")\n",
    "print(f\"Graph [Distances - N_samples x N_samples]: \\n{face_method.get_graph()}\\n\")\n",
    "print(f\"Graph = Graph + face_method.get_start_node_edges() if the start node counterfactual is not in X\")\n",
    "print(f\"Paths [Indexes]: {face_method.get_explain_paths()}\\n\")\n",
    "print(f\"Candidates for Counterfactuals [Indexes]: {face_method.get_explain_candidates()}\")\n",
    "\n",
    "counterfactuals_as_indexes = face_method.get_counterfactuals(as_indexes=True)\n",
    "counterfactuals = face_method.get_counterfactuals()\n",
    "counterfactuals_data, counterfactuals_target = face_method.get_counterfactuals_as_data()\n",
    "\n",
    "print(f\"Counterfactuals [Indexes]: {face_method.get_counterfactuals(True)}\")\n",
    "\n",
    "print(f\"\\nfor factual X[{row_indicies[0]}] (as data: {factuals.dataset[0]}), the counterfactual is X[{counterfactuals_as_indexes[0]}] (as classification: {counterfactuals[0]})\")\n",
    "print(f\"\\nCounterfactual for X[0] (X[6]) as target (Y) and data (X): \\nX[{counterfactuals_as_indexes[0]}]: {counterfactuals_data[0]}, Y[{counterfactuals_as_indexes[0]}]: {counterfactuals_target[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c13eb22d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
